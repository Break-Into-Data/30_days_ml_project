{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leowalker/anaconda3/envs/datajobs/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import concurrent.futures\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set the LANGCHAIN_TRACING_V2 environment variable to 'true'\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "\n",
    "# Set the LANGCHAIN_PROJECT environment variable to the desired project name\n",
    "os.environ['LANGCHAIN_PROJECT'] = 'Conversation30DayProject'\n",
    "\n",
    "\n",
    "class Message(BaseModel):\n",
    "    \"\"\"\n",
    "    A model for representing a single message within a message log.\n",
    "    Inlcudes meta data like the user_name, message_type, and a message_id which acts not only as a unique identifier but conversation sequence identifier.\n",
    "    \"\"\"\n",
    "    user_name: str = Field(..., description=\"User name who submitted the message\")\n",
    "    message: str = Field(..., description=\"Full message that the user sent, most likely a question, answer, or comment.\")\n",
    "    message_type: str = Field(...,description=\"Category of the type of interest the message provokes. Question, Answer, Comment, Spam\")\n",
    "    message_id: int = Field(...,description=\"7 digit number, first 5 is the conversations unique identifier and the last 2 is the message sequence number\")\n",
    "\n",
    "\n",
    "class Conversation(BaseModel):\n",
    "    \"\"\"The full message log to review the message history in sequential order.\"\"\"\n",
    "    message_history: List[Message]\n",
    "\n",
    "\n",
    "def create_conv(input_prompt: str):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"You are an expert at generating synthetic coversations. Your task is to create a range of synthetic conversations that comes from the \"Break Into Data\" Discord Server.\n",
    "                    The discord servers's purpose is to help people get data related skills and roles, including data analytics, data science, machine learning, data engineering and ai engineering.\n",
    "                    The Server has a wide range of skillsets ranging from beginners who just started their data journey to proficient and experienced members. \n",
    "                    \n",
    "                    The variety of backgrounds, experience, and interests helps to invoke interesting conversations throughout the discord server. The primary channels is a general, job search support, content creation, share your project, and resources.\n",
    "                    - The channel is small enough that there are only 2-5 users active in a conversation at the same time before another topic get picked up on the channel. \n",
    "                    - Each conversation should be focused around a single general subject but can include tangents that it runs down before coming to a conclusion.\n",
    "                    - While each conversation most likely focuses on question and answer conversations it can also include comments that people share about their expierence or even help to build/rephrase the question.\n",
    "                    - Conversations can also include spam, while this does occure it is less than 15 percent of the messages.\n",
    "                    - Conversations typically range between 3-15 messages\n",
    "                    \n",
    "                    Example of topics include:\n",
    "                    resume help, interview preparation questions, hackathons, networking events, articles, news, youtube videos,\n",
    "                    coding cookbooks, cheatsheets, Linear/logistical Regression, classification, clustering, neural networks, random forests, \n",
    "                \"\"\",\n",
    "            ),\n",
    "            (\"human\", \"{text}\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # llm = ChatGroq(model_name=\"llama3-70b-8192\")\n",
    "    llm = ChatAnthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\") , model_name=\"claude-3-haiku-20240307\")\n",
    "    # llm = ChatGoogleGenerativeAI(model_name=\"gemini-1.5-pro\")\n",
    "\n",
    "    extractor = prompt | llm.with_structured_output(\n",
    "        schema=Conversation,\n",
    "        method=\"function_calling\",\n",
    "        include_raw=False,\n",
    "    )\n",
    "    \n",
    "    return extractor.invoke(input_prompt)\n",
    "\n",
    "\n",
    "def generate_conversation():\n",
    "    return create_conv(\"Generate and save the created conversations.\")\n",
    "\n",
    "\n",
    "def write_conversation_to_csv(conversation, writer):\n",
    "    for message in conversation.message_history:\n",
    "        writer.writerow([message.user_name, message.message, message.message_type, message.message_id])\n",
    "\n",
    "\n",
    "def main(conv_filepath, num_conversations=3):\n",
    "    file_exists = os.path.exists(conv_filepath)\n",
    "\n",
    "    with open(conv_filepath, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        if not file_exists:\n",
    "            writer.writerow(['user_name', 'message', 'message_type', 'message_id'])\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = []\n",
    "            for _ in range(num_conversations):\n",
    "                future = executor.submit(generate_conversation)\n",
    "                futures.append(future)\n",
    "\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                try:\n",
    "                    conversation = future.result()\n",
    "                    write_conversation_to_csv(conversation, writer)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error occurred while generating conversation: {str(e)}\")\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while generating conversation: 1 validation error for Conversation\n",
      "message_history\n",
      "  value is not a valid list (type=type_error.list)\n",
      "Error occurred while generating conversation: 1 validation error for Conversation\n",
      "message_history\n",
      "  value is not a valid list (type=type_error.list)\n",
      "Error occurred while generating conversation: 1 validation error for Conversation\n",
      "message_history\n",
      "  field required (type=value_error.missing)\n"
     ]
    }
   ],
   "source": [
    "conv_filepath = './data/conversations.csv'\n",
    "for _ in range(40):\n",
    "    main(conv_filepath, 2)\n",
    "    # time.sleep(6) # Groq has a rate limit of 3k tokens per minute so need to slow it down sometimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "message_type\n",
       "Answer          605\n",
       "Question        547\n",
       "Comment         261\n",
       "question         20\n",
       "answer           19\n",
       "comment           8\n",
       "Response          5\n",
       "Advice            3\n",
       "Spam              2\n",
       "Resource          1\n",
       "Suggestion        1\n",
       "Appreciation      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(conv_filepath)\n",
    "\n",
    "# get the value count of each message type\n",
    "df['message_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>message</th>\n",
       "      <th>message_type</th>\n",
       "      <th>message_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DataNewbie</td>\n",
       "      <td>Hey guys, I'm having trouble with my linear re...</td>\n",
       "      <td>Question</td>\n",
       "      <td>12345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DataWizard</td>\n",
       "      <td>What's your data look like? Are you using any ...</td>\n",
       "      <td>Comment</td>\n",
       "      <td>12346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DataNewbie</td>\n",
       "      <td>I'm using a dataset with 1000 samples and 10 f...</td>\n",
       "      <td>Answer</td>\n",
       "      <td>12347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DataWizard</td>\n",
       "      <td>Have you checked for multicollinearity? Maybe ...</td>\n",
       "      <td>Comment</td>\n",
       "      <td>12348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DataNewbie</td>\n",
       "      <td>Yeah, I did check for multicollinearity and re...</td>\n",
       "      <td>Answer</td>\n",
       "      <td>12349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_name                                            message message_type  \\\n",
       "0  DataNewbie  Hey guys, I'm having trouble with my linear re...     Question   \n",
       "1  DataWizard  What's your data look like? Are you using any ...      Comment   \n",
       "2  DataNewbie  I'm using a dataset with 1000 samples and 10 f...       Answer   \n",
       "3  DataWizard  Have you checked for multicollinearity? Maybe ...      Comment   \n",
       "4  DataNewbie  Yeah, I did check for multicollinearity and re...       Answer   \n",
       "\n",
       "   message_id  \n",
       "0       12345  \n",
       "1       12346  \n",
       "2       12347  \n",
       "3       12348  \n",
       "4       12349  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datajobs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
