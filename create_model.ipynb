{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "\n",
    "import keras\n",
    "import openai\n",
    "import dotenv\n",
    "import bentoml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create a console handler and set the log level\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Create a formatter and set it to the console handler\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "# Add the console handler to the logger\n",
    "logger.addHandler(console_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey guys, I'm having trouble with my linear re...</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's your data look like? Are you using any ...</td>\n",
       "      <td>Comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm using a dataset with 1000 samples and 10 f...</td>\n",
       "      <td>Answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Have you checked for multicollinearity? Maybe ...</td>\n",
       "      <td>Comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yeah, I did check for multicollinearity and re...</td>\n",
       "      <td>Answer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  Hey guys, I'm having trouble with my linear re...  Question\n",
       "1  What's your data look like? Are you using any ...   Comment\n",
       "2  I'm using a dataset with 1000 samples and 10 f...    Answer\n",
       "3  Have you checked for multicollinearity? Maybe ...   Comment\n",
       "4  Yeah, I did check for multicollinearity and re...    Answer"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(\"conversations.csv\")[[\"message\", \"message_type\"]]\n",
    "raw_df.rename(columns={\n",
    "    \"message\": \"text\", \n",
    "    \"message_type\": \"label\"\n",
    "}, inplace=True)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Answer          605\n",
       "Question        547\n",
       "Comment         261\n",
       "question         20\n",
       "answer           19\n",
       "comment           8\n",
       "Response          5\n",
       "Advice            3\n",
       "Spam              2\n",
       "Resource          1\n",
       "Suggestion        1\n",
       "Appreciation      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "answer      624\n",
       "question    567\n",
       "comment     269\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allowed_labels = {'question', 'answer', 'comment'}\n",
    "raw_df['label'] = raw_df['label'].str.lower()\n",
    "raw_df = raw_df[raw_df['label'].isin(allowed_labels)]\n",
    "raw_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "embedding_model = \"text-embedding-3-large\"\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "number_of_samples = len(raw_df)\n",
    "\n",
    "for idx, text in enumerate(raw_df['text']):\n",
    "    print(f\"{idx}/{number_of_samples} - {text}\")\n",
    "    try:\n",
    "        response = client.embeddings.create(\n",
    "            input=text,\n",
    "            model=embedding_model,\n",
    "        )\n",
    "        vector = response.data[0].embedding\n",
    "        vectors.append(vector)\n",
    "    except openai.APIError:\n",
    "        logger.error(f\"Failed to embed text: {text}\")\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "    except openai.error.ServiceUnavailableError:\n",
    "        logger.error(\"OpenAI Service is unavailable\")\n",
    "        break\n",
    "    \n",
    "vectors_arr = np.asarray(vectors, dtype=np.float64)\n",
    "np.save(\"vectors.npy\", vectors_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>Hi! Yeah, I'd be happy to help. K-means is a t...</td>\n",
       "      <td>answer</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.012134386226534843, -9.189688717015088e-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>Data analysts usually need strong SQL, spreads...</td>\n",
       "      <td>answer</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0025824133772403, -0.022944526746869087, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Awesome, thanks so much! I'll definitely look ...</td>\n",
       "      <td>comment</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.022549433633685112, 0.03613811731338501, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Hey everyone, I'm just starting to learn about...</td>\n",
       "      <td>question</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0012090475065633655, 0.02343117631971836, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>Awesome, thanks for the tips! I'll make sure t...</td>\n",
       "      <td>question</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.012299810536205769, 0.01986454799771309, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     label  label_id  \\\n",
       "894   Hi! Yeah, I'd be happy to help. K-means is a t...    answer         1   \n",
       "1109  Data analysts usually need strong SQL, spreads...    answer         1   \n",
       "413   Awesome, thanks so much! I'll definitely look ...   comment         2   \n",
       "524   Hey everyone, I'm just starting to learn about...  question         0   \n",
       "1039  Awesome, thanks for the tips! I'll make sure t...  question         0   \n",
       "\n",
       "                                                 vector  \n",
       "894   [-0.012134386226534843, -9.189688717015088e-05...  \n",
       "1109  [0.0025824133772403, -0.022944526746869087, -0...  \n",
       "413   [0.022549433633685112, 0.03613811731338501, -0...  \n",
       "524   [0.0012090475065633655, 0.02343117631971836, -...  \n",
       "1039  [0.012299810536205769, 0.01986454799771309, -0...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_encoder(label):\n",
    "    return {\n",
    "        \"question\": 0,\n",
    "        \"answer\": 1,\n",
    "        \"comment\": 2\n",
    "    }[label]\n",
    "\n",
    "vectors_arr = np.load('vectors.npy')\n",
    "df_full = raw_df.copy()\n",
    "df_full['label'] = raw_df['label']\n",
    "df_full['label_id'] = df_full['label'].apply(label_encoder)\n",
    "df_full['vector'] = list(vectors_arr)\n",
    "\n",
    "train_size = 0.8\n",
    "\n",
    "df_train = df_full.sample(frac=train_size, random_state=42)\n",
    "df_test = df_full.drop(df_train.index).reset_index(drop=True)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,440,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,219</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │     \u001b[38;5;34m9,440,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │         \u001b[38;5;34m9,219\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,449,475</span> (36.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,449,475\u001b[0m (36.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,449,475</span> (36.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,449,475\u001b[0m (36.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_size = len(df_train['vector'].iloc[0])\n",
    "num_classes = len(df_full['label'].unique())\n",
    "input_layer = keras.Input((embedding_size, ))\n",
    "hidden_layer = layers.Dense(embedding_size, activation='relu')(input_layer)\n",
    "output_layer = layers.Dense(num_classes, activation='sigmoid')(hidden_layer)\n",
    "classifier = keras.Model(\n",
    "    inputs=[\n",
    "        input_layer\n",
    "    ],\n",
    "    outputs=output_layer,\n",
    ")\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(\n",
    "    # loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights:  {1: 2.3407, 0: 2.6013, 2: 5.3091}\n",
      "Epoch 1/40\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 123ms/step - accuracy: 0.7553 - loss: 0.6151 - val_accuracy: 0.9110 - val_loss: 0.2603\n",
      "Epoch 2/40\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.9430 - loss: 0.1549 - val_accuracy: 0.9110 - val_loss: 0.2317\n",
      "Epoch 3/40\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 0.9708 - loss: 0.0927 - val_accuracy: 0.9178 - val_loss: 0.2155\n",
      "Epoch 4/40\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - accuracy: 0.9809 - loss: 0.0545 - val_accuracy: 0.9247 - val_loss: 0.2181\n",
      "Epoch 5/40\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - accuracy: 0.9908 - loss: 0.0318 - val_accuracy: 0.9144 - val_loss: 0.2535\n",
      "Epoch 6/40\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - accuracy: 0.9971 - loss: 0.0171 - val_accuracy: 0.9212 - val_loss: 0.2566\n",
      "Epoch 7/40\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - accuracy: 0.9987 - loss: 0.0097 - val_accuracy: 0.9041 - val_loss: 0.2819\n",
      "Epoch 8/40\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - accuracy: 0.9982 - loss: 0.0099 - val_accuracy: 0.9247 - val_loss: 0.2837\n",
      "Epoch 9/40\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - accuracy: 0.9991 - loss: 0.0043 - val_accuracy: 0.9247 - val_loss: 0.3019\n",
      "Epoch 10/40\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9247 - val_loss: 0.3062\n",
      "Epoch 11/40\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9247 - val_loss: 0.3107\n",
      "Epoch 12/40\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9281 - val_loss: 0.3164\n",
      "Epoch 13/40\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9281 - val_loss: 0.3275\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 40\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Split the x and y components of the train and validation subsets.\n",
    "y_train = df_train['label_id']\n",
    "x_train = np.stack(df_train['vector'])\n",
    "y_test = df_test['label_id']\n",
    "x_test = np.stack(df_test['vector'])\n",
    "\n",
    "# Train the model for the desired number of epochs.\n",
    "callback = keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\n",
    "\n",
    "class_counts = df_train['label_id'].value_counts()\n",
    "total_count = class_counts.sum()\n",
    "class_weight = {\n",
    "    label: round(total_count / count, 4)\n",
    "    for label, count in class_counts.items()\n",
    "}\n",
    "print(\"Class Weights: \", class_weight)\n",
    "\n",
    "history = classifier.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[callback],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    # class_weight=class_weight,\n",
    ")\n",
    "\n",
    "# y_val = df_val['Encoded Label']\n",
    "# x_val = np.stack(df_val['Embeddings'])\n",
    "\n",
    "# print(classifier.evaluate(x=x_val, y=y_val, return_dict=True))\n",
    "\n",
    "# y_hat = classifier.predict(x=x_val)\n",
    "# y_hat = np.argmax(y_hat, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "question\n"
     ]
    }
   ],
   "source": [
    "text = \"You need to run pip install\"\n",
    "text = \"How do I install a package in Python?\"\n",
    "vector = client.embeddings.create(\n",
    "    input=text,\n",
    "    model=embedding_model,\n",
    ").data[0].embedding\n",
    "\n",
    "vector = np.asarray(vector, dtype=np.float64)\n",
    "\n",
    "y_hat = classifier.predict(x=vector.reshape(1, -1))\n",
    "y_hat_max = np.argmax(y_hat, axis=1)[0]\n",
    "\n",
    "label = {\n",
    "    0: \"question\",\n",
    "    1: \"answer\",\n",
    "    2: \"comment\",\n",
    "}[y_hat_max]\n",
    "\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/t5/3qb7sc1j15n13hjcgf4d857h0000gn/T/tmpny827sqgbentoml_model_qa_classifier/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/t5/3qb7sc1j15n13hjcgf4d857h0000gn/T/tmpny827sqgbentoml_model_qa_classifier/assets\n"
     ]
    }
   ],
   "source": [
    "bento_model = bentoml.tensorflow.save_model(\"qa_classifier\", classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_Model__fs',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__attrs_attrs__',\n",
       " '__attrs_init__',\n",
       " '__attrs_own_setattr__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__match_args__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_compress',\n",
       " '_custom_objects',\n",
       " '_export_ext',\n",
       " '_export_name',\n",
       " '_from_compressed',\n",
       " '_fs',\n",
       " '_info',\n",
       " '_model',\n",
       " '_runnable',\n",
       " '_tag',\n",
       " '_write_custom_objects',\n",
       " '_write_info',\n",
       " 'create',\n",
       " 'creation_time',\n",
       " 'custom_objects',\n",
       " 'enter_cloudpickle_context',\n",
       " 'exit_cloudpickle_context',\n",
       " 'export',\n",
       " 'file_size',\n",
       " 'flush',\n",
       " 'from_fs',\n",
       " 'get_typename',\n",
       " 'guess_format',\n",
       " 'import_from',\n",
       " 'info',\n",
       " 'load_model',\n",
       " 'path',\n",
       " 'path_of',\n",
       " 'save',\n",
       " 'tag',\n",
       " 'to_runnable',\n",
       " 'to_runner',\n",
       " 'validate',\n",
       " 'with_options']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(bento_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_trackable_child',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_build_shapes_dict',\n",
       " '_checkpoint_dependencies',\n",
       " '_copy_trackable_to_cpu',\n",
       " '_default_save_signature',\n",
       " '_deferred_dependencies',\n",
       " '_delete_tracking',\n",
       " '_deserialization_dependencies',\n",
       " '_deserialize_from_proto',\n",
       " '_export_to_saved_model_graph',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_handle_deferred_dependencies',\n",
       " '_inbound_nodes',\n",
       " '_layers',\n",
       " '_lookup_dependency',\n",
       " '_losses',\n",
       " '_losses_override',\n",
       " '_maybe_initialize_trackable',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_object_identifier',\n",
       " '_operations',\n",
       " '_outbound_nodes',\n",
       " '_preload_simple_restoration',\n",
       " '_restore_from_tensors',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_serialize_to_proto',\n",
       " '_serialize_to_tensors',\n",
       " '_setattr_tracking',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_track_trackable',\n",
       " '_trackable_children',\n",
       " '_tracked',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " 'graph_debug_info',\n",
       " 'optimizer',\n",
       " 'output_names',\n",
       " 'signatures',\n",
       " 'tensorflow_git_version',\n",
       " 'tensorflow_version']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(bento_model.load_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bentoml.tensorflow.load_model(\"qa_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_UserObject' object has no attribute 'load_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_UserObject' object has no attribute 'load_model'"
     ]
    }
   ],
   "source": [
    "model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datajobs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
